{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DzihywKtPoj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_u2JoGWxtx19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j3E0T42Stx5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/yichuan-w/LEANN/blob/main/docs/configuration-guide.md"
      ],
      "metadata": {
        "id": "MRY5JVMJEbPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yichuan-w/LEANN.git leann\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-570SHqtx8e",
        "outputId": "48ee71bc-822a-42c5-968d-18b5073165ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'leann'...\n",
            "remote: Enumerating objects: 7157, done.\u001b[K\n",
            "remote: Counting objects: 100% (1281/1281), done.\u001b[K\n",
            "remote: Compressing objects: 100% (227/227), done.\u001b[K\n",
            "remote: Total 7157 (delta 1155), reused 1062 (delta 1054), pack-reused 5876 (from 2)\u001b[K\n",
            "Receiving objects: 100% (7157/7157), 70.87 MiB | 22.22 MiB/s, done.\n",
            "Resolving deltas: 100% (3957/3957), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd leann"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNSWqRZpuHDl",
        "outputId": "fdc8ab98-79e2-4dcf-8c78-4acb4017ab67"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/leann\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip install leann"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLijrD8OuOOj",
        "outputId": "22b88a3e-914e-4ae9-9f77-042420d89ce9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.12.11 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m140 packages\u001b[0m \u001b[2min 2.35s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m28 packages\u001b[0m \u001b[2min 2.08s\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 45ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m29 packages\u001b[0m \u001b[2min 67ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1maiosqlite\u001b[0m\u001b[2m==0.21.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbanks\u001b[0m\u001b[2m==2.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcolorama\u001b[0m\u001b[2m==0.4.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdataclasses-json\u001b[0m\u001b[2m==0.6.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdeprecated\u001b[0m\u001b[2m==1.2.18\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdirtyjson\u001b[0m\u001b[2m==1.0.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfiletype\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgitignore-parser\u001b[0m\u001b[2m==0.1.13\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgriffe\u001b[0m\u001b[2m==1.14.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mleann\u001b[0m\u001b[2m==0.3.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mleann-backend-diskann\u001b[0m\u001b[2m==0.3.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mleann-backend-hnsw\u001b[0m\u001b[2m==0.3.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mleann-core\u001b[0m\u001b[2m==0.3.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mllama-index-core\u001b[0m\u001b[2m==0.14.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mllama-index-embeddings-huggingface\u001b[0m\u001b[2m==0.6.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mllama-index-instrumentation\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mllama-index-readers-file\u001b[0m\u001b[2m==0.5.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mllama-index-workflows\u001b[0m\u001b[2m==2.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarshmallow\u001b[0m\u001b[2m==3.26.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmypy-extensions\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpdfminer-six\u001b[0m\u001b[2m==20250506\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpdfplumber\u001b[0m\u001b[2m==0.11.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpymupdf\u001b[0m\u001b[2m==1.26.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpypdf\u001b[0m\u001b[2m==6.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpypdf2\u001b[0m\u001b[2m==3.0.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpypdfium2\u001b[0m\u001b[2m==4.30.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==75.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==80.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mstriprtf\u001b[0m\u001b[2m==0.0.26\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-inspect\u001b[0m\u001b[2m==0.9.0\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip install ollama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scqo9wNvuejc",
        "outputId": "6a731bdb-4664-41bb-d9aa-64509f0df7dc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.12.11 environment at: /usr\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mollama==0.6.0                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhttpx==0.28.1                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mpydantic==2.11.9                                                              \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mpydantic-core==2.33.2                                                         \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2manyio==4.10.0                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mcertifi==2025.8.3                                                             \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mhttpcore==1.0.9                                                               \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2midna==3.10                                                                    \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mannotated-types==0.7.0                                                        \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mtyping-extensions==4.15.0                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mtyping-extensions==4.15.0                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mtyping-inspection==0.4.1                                                      \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2msniffio==1.3.1                                                                \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mh11==0.16.0                                                                   \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2m                                                                              \u001b[0m\r\u001b[2K\u001b[2mResolved \u001b[1m13 packages\u001b[0m \u001b[2min 139ms\u001b[0m\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/0)                                                   \r\u001b[2K\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2m\u001b[0m (1/1)                                                                        \r\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 18ms\u001b[0m\u001b[0m\n",
            "░░░░░░░░░░░░░░░░░░░░ [0/0] \u001b[2mInstalling wheels...                                 \u001b[0m\r\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/1] \u001b[2mInstalling wheels...                                 \u001b[0m\r\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/1] \u001b[2mollama==0.6.0                                        \u001b[0m\r\u001b[2K████████████████████ [1/1] \u001b[2mollama==0.6.0                                        \u001b[0m\r\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mollama\u001b[0m\u001b[2m==0.6.0\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "curl -fsSL https://ollama.com/install.sh | sh\n",
        "nohup ollama serve &\n",
        "ollama pull llama3:8b\n",
        "ollama list"
      ],
      "metadata": {
        "id": "ol5LxIX1un-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujHu6ASquxMM",
        "outputId": "e5d226a1-8699-4958-8b59-d90eceff5672"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup ollama serve &\n",
        "!ollama pull gemma3:1b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiWQpErquxnE",
        "outputId": "94b927aa-fc5e-46f3-df96-e81fd54912ee"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull embeddinggemma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOC24PgmwK1Y",
        "outputId": "84e9ed9a-d307-48a7-8390-27192e0662fb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama list\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjbbh4YyxGVY",
        "outputId": "d4cc0705-4d4a-4e24-e0db-7be1843f7d99"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME                     ID              SIZE      MODIFIED       \n",
            "embeddinggemma:latest    85462619ee72    621 MB    18 minutes ago    \n",
            "qwen3:4b                 e55aed6fe643    2.5 GB    20 minutes ago    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from leann import LeannBuilder, LeannSearcher, LeannChat\n",
        "from pathlib import Path\n",
        "INDEX_PATH = str(Path(\"./\").resolve() / \"demo.leann\")"
      ],
      "metadata": {
        "id": "Z_YAA9szvx7u"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from leann import LeannBuilder, LeannSearcher, LeannChat\n",
        "from pathlib import Path\n",
        "INDEX_PATH = str(Path(\"./\").resolve() / \"demo.leann\")\n",
        "\n",
        "builder = LeannBuilder(backend_name=\"hnsw\",\n",
        "                       embedding_model=\"embeddinggemma:latest\",\n",
        "                       embedding_mode=\"ollama\",\n",
        "                       gragh_degree=32,\n",
        "                       build_complexity=64\n",
        "                        )\n",
        "builder.add_text(\"Machine learning transforms industries\")\n",
        "builder.add_text(\"Neural networks process complex data\")\n",
        "builder.add_text(\"Leann is a great storage saving engine for RAG on your MacBook\")\n",
        "builder.build_index(INDEX_PATH)\n",
        "print(\"Index built with embeddinggemma:latest (ollama)\")\n",
        "from leann.api import LeannSearcher\n",
        "\n",
        "searcher = LeannSearcher(\n",
        "    INDEX_PATH,\n",
        "    embedding_model=\"embeddinggemma:latest\",\n",
        "    embedding_mode=\"ollama\",\n",
        "    search_complexity=32\n",
        "    )\n",
        "result = searcher.search(\"What is Leann?\", top_k=1)\n",
        "\n",
        "print(\"Search result:\")\n",
        "if result:\n",
        "  print(result[0].text)\n",
        "else:\n",
        "  print(\"No match found.\")\n",
        "print(\"Structure of result:\", result)\n",
        "\n",
        "\n",
        "chat = LeannChat(\n",
        "    INDEX_PATH,\n",
        "    llm_config={\"type\": \"ollama\", \"model\": \"qwen3:4b\"},\n",
        "    embedding_model=\"embeddinggemma:latest\",\n",
        "    embedding_mode=\"ollama\",\n",
        "    chat_complexity=32\n",
        "    )\n",
        "response = chat.ask(\"What is Leann?\",top_k=1)\n",
        "print(\"Answer:\", response)"
      ],
      "metadata": {
        "id": "8VWo8puMwSDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/leann"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeqQGm5x6XT5",
        "outputId": "4fc276bc-9aaa-442e-bc80-26d3ccfef1cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/leann\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from leann import LeannBuilder, LeannSearcher, LeannChat\n",
        "from pathlib import Path\n",
        "INDEX_PATH = str(Path(\"./\").resolve() / \"demo.leann\")\n",
        "\n",
        "builder = LeannBuilder(backend_name=\"hnsw\",\n",
        "                       embedding_model=\"embeddinggemma:latest\",\n",
        "                       embedding_mode=\"ollama\"\n",
        "                        )\n",
        "builder.add_text(\"Machine learning transforms industries\")\n",
        "builder.add_text(\"Neural networks process complex data\")\n",
        "builder.add_text(\"Leann is a great storage saving engine for RAG on your MacBook\")\n",
        "builder.build_index(INDEX_PATH)\n",
        "print(\"Index built with embeddinggemma:latest (ollama)\")\n",
        "from leann.api import LeannSearcher\n",
        "\n",
        "searcher = LeannSearcher(\n",
        "    INDEX_PATH,\n",
        "    embedding_model=\"embeddinggemma:latest\",\n",
        "    embedding_mode=\"ollama\"\n",
        "    )\n",
        "result = searcher.search(\"What is Leann?\", top_k=1)\n",
        "\n",
        "print(\"Search result:\")\n",
        "if result:\n",
        "  print(result[0].text)\n",
        "else:\n",
        "  print(\"No match found.\")\n",
        "print(\"Structure of result:\", result)\n",
        "\n",
        "\n",
        "chat = LeannChat(\n",
        "    INDEX_PATH,\n",
        "    llm_config={\"type\": \"ollama\", \"model\": \"qwen3:4b\"},\n",
        "    embedding_model=\"embeddinggemma:latest\",\n",
        "    embedding_mode=\"ollama\"\n",
        "    )\n",
        "response = chat.ask(\"What is Leann?\", top_k=1)\n",
        "print(\"Answer:\", response)"
      ],
      "metadata": {
        "id": "Se2NMpFR4Kx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!ollama pull gemma3:1b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGbEzrtG4UAf",
        "outputId": "7772900f-a8d2-4a4f-ce4c-c537e6a25e28"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftOqYc-F7_ZB",
        "outputId": "6c6229c8-f5c5-4792-f1b7-9b4c9c67c6d8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME                     ID              SIZE      MODIFIED       \n",
            "gemma3:1b                8648f39daa8f    815 MB    3 seconds ago     \n",
            "embeddinggemma:latest    85462619ee72    621 MB    51 minutes ago    \n",
            "qwen3:4b                 e55aed6fe643    2.5 GB    53 minutes ago    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from leann import LeannBuilder, LeannSearcher, LeannChat\n",
        "from pathlib import Path\n",
        "INDEX_PATH = str(Path(\"./\").resolve() / \"demo.leann\")\n",
        "\n",
        "builder = LeannBuilder(backend_name=\"hnsw\",\n",
        "                       embedding_model=\"embeddinggemma:latest\",\n",
        "                       embedding_mode=\"ollama\"\n",
        "                        )\n",
        "builder.add_text(\"Machine learning transforms industries\")\n",
        "builder.add_text(\"Neural networks process complex data\")\n",
        "builder.add_text(\"Leann is a great storage saving engine for RAG on your MacBook\")\n",
        "builder.build_index(INDEX_PATH)\n",
        "print(\"Index built with embeddinggemma:latest (ollama)\")\n",
        "from leann.api import LeannSearcher\n",
        "\n",
        "searcher = LeannSearcher(\n",
        "    INDEX_PATH,\n",
        "    embedding_model=\"embeddinggemma:latest\",\n",
        "    embedding_mode=\"ollama\"\n",
        "    )\n",
        "result = searcher.search(\"What is Leann?\", top_k=1)\n",
        "\n",
        "print(\"Search result:\")\n",
        "if result:\n",
        "  print(result[0].text)\n",
        "else:\n",
        "  print(\"No match found.\")\n",
        "print(\"Structure of result:\", result)\n",
        "\n",
        "\n",
        "chat = LeannChat(\n",
        "    INDEX_PATH,\n",
        "    llm_config={\"type\": \"ollama\", \"model\": \"gemma3:1b\"},\n",
        "    embedding_model=\"embeddinggemma:latest\",\n",
        "    embedding_mode=\"ollama\"\n",
        "    )\n",
        "response = chat.ask(\"What is Leann?\", top_k=1)\n",
        "print(\"Answer:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wjl1vqYC8GQ4",
        "outputId": "b103a713-80ae-4801-ce9a-82fa2a421428"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Writing passages: 100%|██████████| 3/3 [00:00<00:00, 6442.86chunk/s]\n",
            "Computing Ollama embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting conversion: /content/leann/demo.index -> /content/leann/demo.csr.tmp\n",
            "[0.00s] Reading Index HNSW header...\n",
            "[0.00s]   Header read: d=768, ntotal=3\n",
            "[0.00s] Reading HNSW struct vectors...\n",
            "  Reading vector (dtype=<class 'numpy.float64'>, fmt='d')... Count=6, Bytes=48\n",
            "[0.00s]   Read assign_probas (6)\n",
            "  Reading vector (dtype=<class 'numpy.int32'>, fmt='i')... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count=7, Bytes=28\n",
            "[0.20s]   Read cum_nneighbor_per_level (7)\n",
            "  Reading vector (dtype=<class 'numpy.int32'>, fmt='i')... Count=3, Bytes=12\n",
            "[0.34s]   Read levels (3)\n",
            "[0.49s]   Probing for compact storage flag...\n",
            "[0.49s]   Found compact flag: False\n",
            "[0.49s]   Compact flag is False, reading original format...\n",
            "[0.49s]   Probing for potential extra byte before non-compact offsets...\n",
            "[0.49s]   Found and consumed an unexpected 0x00 byte.\n",
            "  Reading vector (dtype=<class 'numpy.uint64'>, fmt='Q')... Count=4, Bytes=32\n",
            "[0.49s]   Read offsets (4)\n",
            "[0.64s]   Attempting to read neighbors vector...\n",
            "  Reading vector (dtype=<class 'numpy.int32'>, fmt='i')... Count=192, Bytes=768\n",
            "[0.64s]   Read neighbors (192)\n",
            "[0.78s]   Read scalar params (ep=1, max_lvl=0)\n",
            "[0.78s] Checking for storage data...\n",
            "[0.78s]   Found storage fourcc: 49467849.\n",
            "[0.78s] Converting to CSR format...\n",
            "[0.78s]   Conversion loop finished.                        \n",
            "[0.78s] Running validation checks...\n",
            "    Checking total valid neighbor count...\n",
            "    OK: Total valid neighbors = 6\n",
            "    Checking final pointer indices...\n",
            "    OK: Final pointers match data size.\n",
            "[0.78s] Deleting original neighbors and offsets arrays...\n",
            "    CSR Stats: |data|=6, |level_ptr|=6\n",
            "[0.93s] Writing CSR HNSW graph data in FAISS-compatible order...\n",
            "   Pruning embeddings: Writing NULL storage marker.\n",
            "[1.10s] Conversion complete.\n",
            "Index built with embeddinggemma:latest (ollama)\n",
            "Search result:\n",
            "Machine learning transforms industries\n",
            "Structure of result: [SearchResult(id='0', score=np.float32(0.7503269), text='Machine learning transforms industries', metadata={})]\n",
            "Answer: Since the context is about machine learning transforming industries, and you're asking about \"Leann,\" there's no connection to the provided text. Therefore, I cannot answer your question. \n",
            "\n",
            "I need the original question or context to provide a helpful answer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from leann import LeannBuilder, LeannSearcher, LeannChat\n",
        "from pathlib import Path\n",
        "INDEX_PATH = str(Path(\"./\").resolve() / \"demo.leann\")\n",
        "\n",
        "builder = LeannBuilder(backend_name=\"hnsw\",\n",
        "                       embedding_model=\"embeddinggemma:latest\",\n",
        "                       embedding_mode=\"ollama\"\n",
        "                        )\n",
        "\n",
        "builder.add_text(\"Leann is a great storage saving engine for RAG on your MacBook\")\n",
        "builder.build_index(INDEX_PATH)\n",
        "print(\"Index built with embeddinggemma:latest (ollama)\")\n",
        "from leann.api import LeannSearcher\n",
        "\n",
        "searcher = LeannSearcher(\n",
        "    INDEX_PATH,\n",
        "    embedding_model=\"embeddinggemma:latest\",\n",
        "    embedding_mode=\"ollama\"\n",
        "    )\n",
        "result = searcher.search(\"What is Leann?\", top_k=1)\n",
        "\n",
        "print(\"Search result:\")\n",
        "if result:\n",
        "  print(result[0].text)\n",
        "else:\n",
        "  print(\"No match found.\")\n",
        "print(\"Structure of result:\", result)\n",
        "\n",
        "\n",
        "chat = LeannChat(\n",
        "    INDEX_PATH,\n",
        "    llm_config={\"type\": \"ollama\", \"model\": \"gemma3:1b\"},\n",
        "    embedding_model=\"embeddinggemma:latest\",\n",
        "    embedding_mode=\"ollama\"\n",
        "    )\n",
        "response = chat.ask(\"What is Leann?\", top_k=1)\n",
        "print(\"Answer:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tROtHK-J8xKR",
        "outputId": "29375811-8100-4f3a-894b-c0469f4dad9c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Writing passages: 100%|██████████| 1/1 [00:00<00:00, 4624.37chunk/s]\n",
            "Computing Ollama embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting conversion: /content/leann/demo.index -> /content/leann/demo.csr.tmp\n",
            "[0.00s] Reading Index HNSW header...\n",
            "[0.00s]   Header read: d=768, ntotal=1\n",
            "[0.00s] Reading HNSW struct vectors...\n",
            "  Reading vector (dtype=<class 'numpy.float64'>, fmt='d')... Count=6, Bytes=48\n",
            "[0.00s]   Read assign_probas (6)\n",
            "  Reading vector (dtype=<class 'numpy.int32'>, fmt='i')... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count=7, Bytes=28\n",
            "[0.16s]   Read cum_nneighbor_per_level (7)\n",
            "  Reading vector (dtype=<class 'numpy.int32'>, fmt='i')... Count=1, Bytes=4\n",
            "[0.31s]   Read levels (1)\n",
            "[0.46s]   Probing for compact storage flag...\n",
            "[0.46s]   Found compact flag: False\n",
            "[0.46s]   Compact flag is False, reading original format...\n",
            "[0.46s]   Probing for potential extra byte before non-compact offsets...\n",
            "[0.46s]   Found and consumed an unexpected 0x00 byte.\n",
            "  Reading vector (dtype=<class 'numpy.uint64'>, fmt='Q')... Count=2, Bytes=16\n",
            "[0.46s]   Read offsets (2)\n",
            "[0.60s]   Attempting to read neighbors vector...\n",
            "  Reading vector (dtype=<class 'numpy.int32'>, fmt='i')... Count=64, Bytes=256\n",
            "[0.61s]   Read neighbors (64)\n",
            "[0.77s]   Read scalar params (ep=0, max_lvl=0)\n",
            "[0.77s] Checking for storage data...\n",
            "[0.77s]   Found storage fourcc: 49467849.\n",
            "[0.77s] Converting to CSR format...\n",
            "[0.77s]   Conversion loop finished.                        \n",
            "[0.77s] Running validation checks...\n",
            "    Checking total valid neighbor count...\n",
            "    OK: Total valid neighbors = 0\n",
            "    Checking final pointer indices...\n",
            "    OK: Final pointers match data size.\n",
            "[0.77s] Deleting original neighbors and offsets arrays...\n",
            "    CSR Stats: |data|=0, |level_ptr|=2\n",
            "[0.91s] Writing CSR HNSW graph data in FAISS-compatible order...\n",
            "   Pruning embeddings: Writing NULL storage marker.\n",
            "[1.03s] Conversion complete.\n",
            "Index built with embeddinggemma:latest (ollama)\n",
            "Search result:\n",
            "Leann is a great storage saving engine for RAG on your MacBook\n",
            "Structure of result: [SearchResult(id='0', score=np.float32(0.6394725), text='Leann is a great storage saving engine for RAG on your MacBook', metadata={})]\n",
            "Answer: Based on the context, Leann is a storage-saving engine specifically designed for RAG (Retrieval-Augmented Generation) on a MacBook.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!leann build mydemo --docs ./data --force"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irELbuiT9Csa",
        "outputId": "d7a3bb46-fd26-4081-dd81-1ceeec01e6e7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 Indexing 1 path:\n",
            "  📁 Directories (1):\n",
            "    1. /content/leann/data\n",
            "Loading documents from 1 directory (1 total):\n",
            "  📁 Directories: data\n",
            "\n",
            "🔄 Processing 1 directory...\n",
            "Processing directory: data\n",
            "📋 No .gitignore found\n",
            "Loading files: 100% 1/1 [00:01<00:00,  1.99s/it]\n",
            "Loaded 1 documents from data\n",
            "start chunking documents\n",
            "Chunking documents: 100% 1/1 [00:00<00:00, 635.50doc/s]\n",
            "Loaded 1 documents, 1 chunks\n",
            "Building index 'mydemo' with hnsw backend...\n",
            "2025-09-25 22:22:41.186588: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1758838961.564706   17530 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1758838961.664409   17530 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1758838962.387052   17530 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758838962.387113   17530 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758838962.387120   17530 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758838962.387126   17530 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-25 22:22:42.460504: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name facebook/contriever. Creating a new one with mean pooling.\n",
            "WARNING:leann.embedding_compute:Local loading failed (We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Check your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.), trying network download...\n",
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name facebook/contriever. Creating a new one with mean pooling.\n",
            "config.json: 100% 619/619 [00:00<00:00, 2.80MB/s]\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "pytorch_model.bin: 100% 438M/438M [00:06<00:00, 67.9MB/s]\n",
            "model.safetensors:   0% 0.00/438M [00:00<?, ?B/s]\n",
            "tokenizer_config.json: 100% 321/321 [00:00<00:00, 1.87MB/s]\n",
            "\n",
            "vocab.txt: 232kB [00:00, 11.2MB/s]\n",
            "model.safetensors:   0% 12.8k/438M [00:00<7:23:59, 16.4kB/s]\n",
            "tokenizer.json: 466kB [00:00, 26.7MB/s]\n",
            "\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 520kB/s]\n",
            "model.safetensors:   2% 8.28M/438M [00:01<00:56, 7.65MB/s]  \n",
            "Writing passages: 100% 1/1 [00:00<00:00, 5691.05chunk/s]\n",
            "\n",
            "model.safetensors:  54% 237M/438M [00:05<00:03, 65.8MB/s]\n",
            "Batches: 100% 1/1 [00:06<00:00,  6.47s/it]\n",
            "WARNING:leann_backend_hnsw.hnsw_backend:Converting data to float32, shape: (1, 768)\n",
            "M: 64 for level: 0\n",
            "Starting conversion: /content/leann/.leann/indexes/mydemo/documents.index -> /content/leann/.leann/indexes/mydemo/documents.csr.tmp\n",
            "[0.00s] Reading Index HNSW header...\n",
            "[0.00s]   Header read: d=768, ntotal=1\n",
            "[0.00s] Reading HNSW struct vectors...\n",
            "  Reading vector (dtype=<class 'numpy.float64'>, fmt='d')... Count=6, Bytes=48\n",
            "[0.00s]   Read assign_probas (6)\n",
            "model.safetensors: 100% 438M/438M [00:09<00:00, 44.0MB/s]  Reading vector (dtype=<class 'numpy.int32'>, fmt='i')... Count=7, Bytes=28\n",
            "[1.48s]   Read cum_nneighbor_per_level (7)\n",
            "\n",
            "  Reading vector (dtype=<class 'numpy.int32'>, fmt='i')... Count=1, Bytes=4\n",
            "[2.15s]   Read levels (1)\n",
            "[2.78s]   Probing for compact storage flag...\n",
            "[2.78s]   Found compact flag: False\n",
            "[2.78s]   Compact flag is False, reading original format...\n",
            "[2.78s]   Probing for potential extra byte before non-compact offsets...\n",
            "[2.78s]   Found and consumed an unexpected 0x00 byte.\n",
            "  Reading vector (dtype=<class 'numpy.uint64'>, fmt='Q')... Count=2, Bytes=16\n",
            "[2.78s]   Read offsets (2)\n",
            "[3.26s]   Attempting to read neighbors vector...\n",
            "  Reading vector (dtype=<class 'numpy.int32'>, fmt='i')... Count=64, Bytes=256\n",
            "[3.26s]   Read neighbors (64)\n",
            "[3.75s]   Read scalar params (ep=0, max_lvl=0)\n",
            "[3.75s] Checking for storage data...\n",
            "[3.75s]   Found storage fourcc: 49467849.\n",
            "[3.75s] Converting to CSR format...\n",
            "[3.75s]   Conversion loop finished.                        \n",
            "[3.75s] Running validation checks...\n",
            "    Checking total valid neighbor count...\n",
            "    OK: Total valid neighbors = 0\n",
            "    Checking final pointer indices...\n",
            "    OK: Final pointers match data size.\n",
            "[3.75s] Deleting original neighbors and offsets arrays...\n",
            "    CSR Stats: |data|=0, |level_ptr|=2\n",
            "[4.23s] Writing CSR HNSW graph data in FAISS-compatible order...\n",
            "   Pruning embeddings: Writing NULL storage marker.\n",
            "[4.70s] Conversion complete.\n",
            "Index built at /content/leann/.leann/indexes/mydemo/documents.leann\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!leann search mydemo \"What is python?\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hS4A7AEt9Cp9",
        "outputId": "7fe0dd2e-3235-4d26-cc66-5c6f1bc28a93"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_HNSW - CSR NL v4] Reading metadata & CSR indices (manual offset)...\n",
            "[read_HNSW NL v4] Read levels vector, size: 1\n",
            "[read_HNSW NL v4] Reading Compact Storage format indices...\n",
            "[read_HNSW NL v4] Read compact_level_ptr, size: 2\n",
            "[read_HNSW NL v4] Read compact_node_offsets, size: 2\n",
            "[read_HNSW NL v4] Read entry_point: 0, max_level: 0\n",
            "[read_HNSW NL v4] Read storage fourcc: 0x6c6c756e\n",
            "[read_HNSW NL v4 FIX] Detected FileIOReader. Neighbors size field offset: 214\n",
            "[read_HNSW NL v4] Reading neighbors data into memory.\n",
            "[read_HNSW NL v4] Read neighbors data, size: 0\n",
            "[read_HNSW NL v4] Finished reading metadata and CSR indices.\n",
            "INFO: Skipping external storage loading, since is_recompute is true.\n",
            "WARNING:leann.api:  ⚠️  Requested top_k (5) exceeds total documents (1)\n",
            "WARNING:leann.api:  ✅ Auto-adjusted top_k to 1 to match available documents\n",
            "ZmqDistanceComputer initialized: d=768, metric=0\n",
            "Search results for 'What is python?' (top 1):\n",
            "1. Score: 1.106\n",
            "   Python is a high-level, interpreted programming language known for its simplicity, readability, and versatility. Created by Guido van Rossum and first released in 1991, Python emphasizes code readabil...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!leann -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUjYMDJI9Cm5",
        "outputId": "9f3fb3bd-2ddf-4090-ef8e-67a452b9ba18"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: leann [-h] {build,search,ask,list,remove} ...\n",
            "\n",
            "The smallest vector index in the world. RAG Everything with LEANN!\n",
            "\n",
            "positional arguments:\n",
            "  {build,search,ask,list,remove}\n",
            "                        Available commands\n",
            "    build               Build document index\n",
            "    search              Search documents\n",
            "    ask                 Ask questions\n",
            "    list                List all indexes\n",
            "    remove              Remove an index\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "\n",
            "Examples:\n",
            "  leann build my-docs --docs ./documents                                  # Build index from directory\n",
            "  leann build my-code --docs ./src ./tests ./config                      # Build index from multiple directories\n",
            "  leann build my-files --docs ./file1.py ./file2.txt ./docs/             # Build index from files and directories\n",
            "  leann build my-mixed --docs ./readme.md ./src/ ./config.json           # Build index from mixed files/dirs\n",
            "  leann build my-ppts --docs ./ --file-types .pptx,.pdf                  # Index only PowerPoint and PDF files\n",
            "  leann search my-docs \"query\"                                           # Search in my-docs index\n",
            "  leann ask my-docs \"question\"                                           # Ask my-docs index\n",
            "  leann list                                                             # List all stored indexes\n",
            "  leann remove my-docs                                                   # Remove an index (local first, then global)\n",
            "            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!leann ask mydemo What is python?"
      ],
      "metadata": {
        "id": "i7QevaaT_KR6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Docstring:\n",
        "%%python script magic\n",
        "\n",
        "Run cells with python in a subprocess.\n",
        "\n",
        "This is a shortcut for `%%script python`\n",
        "File:      /usr/local/lib/python3.12/dist-packages/IPython/core/magics/script.py"
      ],
      "metadata": {
        "id": "yLmZmzMw_f1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%python script magic\n",
        "!leann ask mydemo \"What is python?\""
      ],
      "metadata": {
        "id": "1gVNYIAw_wPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Hello from a Python subprocess!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e05YVxnoE2W9",
        "outputId": "ac5def00-4b82-449a-d5b0-92d739bdf39f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from a Python subprocess!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ursqlPhZFYGF",
        "outputId": "ee23397c-7c90-46e8-9f26-5821d14f6782"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile run_leann.py\n",
        "\n",
        "# كل الكود الذي في هذه الخلية سيتم حفظه في ملف run_leann.py\n",
        "from leann import LeannBuilder, LeannSearcher, LeannChat\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# تأكد من تثبيت المكتبات الضرورية أولاً\n",
        "# !pip install leann-python ollama\n",
        "\n",
        "# إنشاء مسار للفهرس\n",
        "INDEX_PATH = str(Path(\"./\").resolve() / \"demo.leann\")\n",
        "\n",
        "# حذف الفهرس القديم إذا كان موجودًا لضمان البدء من جديد\n",
        "if os.path.exists(INDEX_PATH):\n",
        "    import shutil\n",
        "    shutil.rmtree(INDEX_PATH)\n",
        "    print(f\"Removed old index at: {INDEX_PATH}\")\n",
        "\n",
        "\n",
        "print(\"Building index...\")\n",
        "builder = LeannBuilder(backend_name=\"hnsw\",\n",
        "                       embedding_model=\"embeddinggemma:latest\",\n",
        "                       embedding_mode=\"ollama\"\n",
        "                        )\n",
        "builder.add_text(\"Machine learning transforms industries\")\n",
        "builder.add_text(\"Neural networks process complex data\")\n",
        "builder.add_text(\"Leann is a great storage saving engine for RAG on your MacBook\")\n",
        "builder.build_index(INDEX_PATH)\n",
        "print(\"Index built with embeddinggemma:latest (ollama)\")\n",
        "\n",
        "\n",
        "print(\"\\nSearching...\")\n",
        "searcher = LeannSearcher(\n",
        "    INDEX_PATH,\n",
        "    embedding_model=\"embeddinggemma:latest\",\n",
        "    embedding_mode=\"ollama\"\n",
        "    )\n",
        "result = searcher.search(\"What is Leann?\", top_k=1)\n",
        "\n",
        "print(\"Search result:\")\n",
        "if result:\n",
        "  print(result[0].text)\n",
        "else:\n",
        "  print(\"No match found.\")\n",
        "print(\"Structure of result:\", result)\n",
        "\n",
        "\n",
        "print(\"\\nChatting...\")\n",
        "chat = LeannChat(\n",
        "    INDEX_PATH,\n",
        "    llm_config={\"type\": \"ollama\", \"model\": \"qwen3:4b\"},\n",
        "    embedding_model=\"embeddinggemma:latest\",\n",
        "    embedding_mode=\"ollama\"\n",
        "    )\n",
        "response = chat.ask(\"What is Leann?\", top_k=1)\n",
        "print(\"Answer:\", response)\n",
        "\n",
        "print(\"\\nScript finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmxwnO6yFVvl",
        "outputId": "dc9a0e45-f837-43e0-fe0d-cfde487194a7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing run_leann.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/run_leann.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN69tkSwFpZk",
        "outputId": "a0fc10ca-716a-4a2e-84c7-f93319bb7f4e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building index...\n",
            "Writing passages: 100% 3/3 [00:00<00:00, 11522.81chunk/s]\n",
            "Computing Ollama embeddings: 100% 1/1 [00:00<00:00,  1.19it/s]\n",
            "M: 64 for level: 0\n",
            "INFO:leann_backend_hnsw.hnsw_backend:INFO: Converting HNSW index to CSR-pruned format...\n",
            "Starting conversion: /content/demo.index -> /content/demo.csr.tmp\n",
            "[0.00s] Reading Index HNSW header...\n",
            "[0.00s]   Header read: d=768, ntotal=3\n",
            "[0.00s] Reading HNSW struct vectors...\n",
            "  Reading vector (dtype=<class 'numpy.float64'>, fmt='d')... Count=6, Bytes=48\n",
            "[0.00s]   Read assign_probas (6)\n",
            "  Reading vector (dtype=<class 'numpy.int32'>, fmt='i')... Count=7, Bytes=28\n",
            "[0.09s]   Read cum_nneighbor_per_level (7)\n",
            "  Reading vector (dtype=<class 'numpy.int32'>, fmt='i')... Count=3, Bytes=12\n",
            "[0.18s]   Read levels (3)\n",
            "[0.26s]   Probing for compact storage flag...\n",
            "[0.26s]   Found compact flag: False\n",
            "[0.26s]   Compact flag is False, reading original format...\n",
            "[0.26s]   Probing for potential extra byte before non-compact offsets...\n",
            "[0.26s]   Found and consumed an unexpected 0x00 byte.\n",
            "  Reading vector (dtype=<class 'numpy.uint64'>, fmt='Q')... Count=4, Bytes=32\n",
            "[0.26s]   Read offsets (4)\n",
            "[0.35s]   Attempting to read neighbors vector...\n",
            "  Reading vector (dtype=<class 'numpy.int32'>, fmt='i')... Count=192, Bytes=768\n",
            "[0.35s]   Read neighbors (192)\n",
            "[0.44s]   Read scalar params (ep=1, max_lvl=0)\n",
            "[0.44s] Checking for storage data...\n",
            "[0.44s]   Found storage fourcc: 49467849.\n",
            "[0.44s] Converting to CSR format...\n",
            "[0.44s]   Conversion loop finished.                        \n",
            "[0.44s] Running validation checks...\n",
            "    Checking total valid neighbor count...\n",
            "    OK: Total valid neighbors = 6\n",
            "    Checking final pointer indices...\n",
            "    OK: Final pointers match data size.\n",
            "[0.44s] Deleting original neighbors and offsets arrays...\n",
            "    CSR Stats: |data|=6, |level_ptr|=6\n",
            "[0.54s] Writing CSR HNSW graph data in FAISS-compatible order...\n",
            "   Pruning embeddings: Writing NULL storage marker.\n",
            "[0.65s] Conversion complete.\n",
            "INFO:leann_backend_hnsw.hnsw_backend:✅ CSR conversion successful.\n",
            "INFO:leann_backend_hnsw.hnsw_backend:INFO: Replaced original index with CSR-pruned version at '/content/demo.index'\n",
            "Index built with embeddinggemma:latest (ollama)\n",
            "\n",
            "Searching...\n",
            "[read_HNSW - CSR NL v4] Reading metadata & CSR indices (manual offset)...\n",
            "[read_HNSW NL v4] Read levels vector, size: 3\n",
            "[read_HNSW NL v4] Reading Compact Storage format indices...\n",
            "[read_HNSW NL v4] Read compact_level_ptr, size: 6\n",
            "[read_HNSW NL v4] Read compact_node_offsets, size: 4\n",
            "[read_HNSW NL v4] Read entry_point: 1, max_level: 0\n",
            "[read_HNSW NL v4] Read storage fourcc: 0x6c6c756e\n",
            "[read_HNSW NL v4 FIX] Detected FileIOReader. Neighbors size field offset: 270\n",
            "[read_HNSW NL v4] Reading neighbors data into memory.\n",
            "[read_HNSW NL v4] Read neighbors data, size: 6\n",
            "[read_HNSW NL v4] Finished reading metadata and CSR indices.\n",
            "INFO: Skipping external storage loading, since is_recompute is true.\n",
            "INFO:leann.api:🔍 LeannSearcher.search() called:\n",
            "INFO:leann.api:  Query: 'What is Leann?'\n",
            "INFO:leann.api:  Top_k: 1\n",
            "INFO:leann.api:  Metadata filters: None\n",
            "INFO:leann.api:  Additional kwargs: {}\n",
            "INFO:leann.embedding_server_manager:Detected Colab environment, using alternative startup strategy\n",
            "INFO:leann.embedding_server_manager:Starting server on port 5559 for Colab environment\n",
            "INFO:leann.embedding_server_manager:Colab Command: /usr/bin/python3 -m leann_backend_hnsw.hnsw_embedding_server --zmq-port 5559 --model-name embeddinggemma:latest --passages-file /content/demo.leann.meta.json --embedding-mode ollama --distance-metric mips\n",
            "INFO:leann.embedding_server_manager:Colab server process started with PID: 25705\n",
            "INFO:leann.embedding_server_manager:Colab embedding server is ready!\n",
            "INFO:leann.api:  Launching server time: 3.0050032138824463 seconds\n",
            "INFO:leann.embedding_server_manager:Reusing in-process server\n",
            "INFO:leann.api:  Generated embedding shape: (1, 768)\n",
            "INFO:leann.api:  Embedding time: 0.6532292366027832 seconds\n",
            "ZmqDistanceComputer initialized: d=768, metric=0\n",
            "INFO:leann_backend_hnsw.hnsw_backend:  Search time in HNSWSearcher.search() backend: 1.7670936584472656 seconds\n",
            "INFO:leann.api:  Search time in search() LEANN searcher: 1.7674527168273926 seconds\n",
            "INFO:leann.api:  Backend returned: labels=1 results\n",
            "INFO:leann.api:  Processing 1 passage IDs:\n",
            "INFO:leann.api:   \u001b[92m✓\u001b[0m \u001b[94m[ 1]\u001b[0m \u001b[93mID:\u001b[0m '0' \u001b[93mScore:\u001b[0m 0.7503 \u001b[93mText:\u001b[0m Machine learning transforms industries\n",
            "INFO:leann.api:  \u001b[92m✓ Final enriched results: 1 passages\u001b[0m\n",
            "Search result:\n",
            "Machine learning transforms industries\n",
            "Structure of result: [SearchResult(id='0', score=np.float32(0.7503269), text='Machine learning transforms industries', metadata={})]\n",
            "\n",
            "Chatting...\n",
            "[read_HNSW - CSR NL v4] Reading metadata & CSR indices (manual offset)...\n",
            "[read_HNSW NL v4] Read levels vector, size: 3\n",
            "[read_HNSW NL v4] Reading Compact Storage format indices...\n",
            "[read_HNSW NL v4] Read compact_level_ptr, size: 6\n",
            "[read_HNSW NL v4] Read compact_node_offsets, size: 4\n",
            "[read_HNSW NL v4] Read entry_point: 1, max_level: 0\n",
            "[read_HNSW NL v4] Read storage fourcc: 0x6c6c756e\n",
            "[read_HNSW NL v4 FIX] Detected FileIOReader. Neighbors size field offset: 270\n",
            "[read_HNSW NL v4] Reading neighbors data into memory.\n",
            "[read_HNSW NL v4] Read neighbors data, size: 6\n",
            "[read_HNSW NL v4] Finished reading metadata and CSR indices.\n",
            "INFO: Skipping external storage loading, since is_recompute is true.\n",
            "INFO:leann.chat:Attempting to create LLM of type='ollama' with model='qwen3:4b'\n",
            "INFO:leann.chat:Initializing OllamaChat with model='qwen3:4b' and host='http://localhost:11434'\n",
            "INFO:leann.api:🔍 LeannSearcher.search() called:\n",
            "INFO:leann.api:  Query: 'What is Leann?'\n",
            "INFO:leann.api:  Top_k: 1\n",
            "INFO:leann.api:  Metadata filters: None\n",
            "INFO:leann.api:  Additional kwargs: {}\n",
            "INFO:leann.embedding_server_manager:Detected Colab environment, using alternative startup strategy\n",
            "INFO:leann.embedding_server_manager:Starting server on port 5560 for Colab environment\n",
            "INFO:leann.embedding_server_manager:Colab Command: /usr/bin/python3 -m leann_backend_hnsw.hnsw_embedding_server --zmq-port 5560 --model-name embeddinggemma:latest --passages-file /content/demo.leann.meta.json --embedding-mode ollama --distance-metric mips\n",
            "INFO:leann.embedding_server_manager:Colab server process started with PID: 25736\n",
            "INFO:leann.embedding_server_manager:Colab embedding server is ready!\n",
            "INFO:leann.api:  Launching server time: 4.011478900909424 seconds\n",
            "INFO:leann.embedding_server_manager:Reusing in-process server\n",
            "INFO:leann.api:  Generated embedding shape: (1, 768)\n",
            "INFO:leann.api:  Embedding time: 0.6257331371307373 seconds\n",
            "ZmqDistanceComputer initialized: d=768, metric=0\n",
            "INFO:leann_backend_hnsw.hnsw_backend:  Search time in HNSWSearcher.search() backend: 1.3038241863250732 seconds\n",
            "INFO:leann.api:  Search time in search() LEANN searcher: 1.304126262664795 seconds\n",
            "INFO:leann.api:  Backend returned: labels=1 results\n",
            "INFO:leann.api:  Processing 1 passage IDs:\n",
            "INFO:leann.api:   \u001b[92m✓\u001b[0m \u001b[94m[ 1]\u001b[0m \u001b[93mID:\u001b[0m '0' \u001b[93mScore:\u001b[0m 0.7503 \u001b[93mText:\u001b[0m Machine learning transforms industries\n",
            "INFO:leann.api:  \u001b[92m✓ Final enriched results: 1 passages\u001b[0m\n",
            "INFO:leann.api:  Search time: 5.942212820053101 seconds\n",
            "INFO:leann.chat:Sending request to Ollama and waiting for response...\n",
            "INFO:leann.api:  Ask time: 374.75620341300964 seconds\n",
            "Answer: <think>\n",
            "Hmm, the user is asking \"What is Leann?\" but they've provided some retrieved context about \"Machine learning transforms industries\". That context doesn't seem to contain any information about Leann. \n",
            "\n",
            "I recall that in the context of machine learning, Leann might refer to Leann's algorithm or something similar, but the retrieved context doesn't mention it at all. The user's question seems disconnected from the provided context. \n",
            "\n",
            "Let me think about possible interpretations:\n",
            "- Could \"Leann\" be a person? Like a researcher or company name?\n",
            "- In machine learning context, there's no prominent \"Leann\" that I know of\n",
            "- Maybe it's a typo? Like \"Learner\" or \"LeNet\" (a type of CNN)?\n",
            "- The context says \"Machine learning transforms industries\" but doesn't specify anything about Leann\n",
            "\n",
            "Given that the retrieved context is completely silent on Leann, and my knowledge base doesn't have a standard machine learning concept called \"Leann\", I should be honest about this. The user might be confused or the context might be incomplete.\n",
            "\n",
            "I should clarify that:\n",
            "1. The provided context doesn't contain information about Leann\n",
            "2. There's no widely recognized machine learning concept named \"Leann\"\n",
            "3. I'll suggest possible typos (like LeNet) since that's a real CNN architecture\n",
            "\n",
            "The user seems to be asking about a specific term in machine learning but the context they provided doesn't help. They might have meant to ask about something else. I'll be helpful by explaining the situation clearly without making up information.\n",
            "\n",
            "Important to note: I shouldn't invent answers since this could mislead the user. Better to be transparent that I don't know what Leann refers to in this context.\n",
            "</think>\n",
            "\n",
            "Based on the retrieved context you provided (\"Machine learning transforms industries\") and my knowledge, **I cannot determine what \"Leann\" is**. Here's why:\n",
            "\n",
            "1. **The retrieved context is silent on \"Leann\"**: The context only discusses how machine learning transforms industries but contains no information about a person, concept, tool, or term called \"Leann.\"\n",
            "\n",
            "2. **\"Leann\" is not a standard machine learning term**: In machine learning literature, there is no widely recognized algorithm, framework, model, or concept named \"Leann.\" This might be:\n",
            "   - A typo (e.g., you meant **LeNet**, a classic convolutional neural network architecture from 1998).\n",
            "   - A name of a specific person (e.g., a researcher or industry professional), but this isn't a standardized term in ML.\n",
            "   - A reference to a niche project, company, or local context not covered in the retrieved material.\n",
            "\n",
            "3. **No credible sources match \"Leann\" in ML**: After cross-checking major ML resources (like TensorFlow, PyTorch documentation, academic papers, and industry standards), there is no established concept called \"Leann.\"\n",
            "\n",
            "**Best answer**:  \n",
            "**\"Leann\" is not a recognized term in machine learning or the retrieved context. It might be a typo (e.g., \"LeNet\"), a name of a specific person, or a reference to something outside the scope of the provided context. Without additional information, I cannot identify what \"Leann\" refers to.**\n",
            "\n",
            "If you meant **LeNet** (a foundational CNN), that would be a valid machine learning concept. If you have more context or clarify the intended term, I’d be happy to help further!\n",
            "\n",
            "Script finished.\n",
            "INFO:leann.embedding_server_manager:Terminating server process (PID: 25736) for backend leann_backend_hnsw.hnsw_embedding_server...\n",
            "INFO:leann.embedding_server_manager:Server process 25736 terminated gracefully.\n",
            "INFO:leann.embedding_server_manager:Server process 25736 cleanup completed\n",
            "INFO:leann.embedding_server_manager:Terminating server process (PID: 25705) for backend leann_backend_hnsw.hnsw_embedding_server...\n",
            "INFO:leann.embedding_server_manager:Server process 25705 terminated gracefully.\n",
            "INFO:leann.embedding_server_manager:Server process 25705 cleanup completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!leann ask mydemo \\\n",
        "  --llm ollama \\\n",
        "  --llm-model gemma3:1b \\\n",
        "  --host http://127.0.0.1:11434"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hOAOUX4_yHa",
        "outputId": "788d6fea-eb91-4de1-892b-12fbe76e4668"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: leann [-h] {build,search,ask,list,remove} ...\n",
            "leann: error: unrecognized arguments: --llm-model gemma3:1b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!leann ask mydemo --llm-model ollama/gemma3:1b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRJLjmsiAaFD",
        "outputId": "1077b5dc-ea17-485a-d153-ba6e306e06fa"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: leann [-h] {build,search,ask,list,remove} ...\n",
            "leann: error: unrecognized arguments: --llm-model ollama/gemma3:1b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!leann ask -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pG9p6BKAoTb",
        "outputId": "f3fcc032-cc0a-48ef-fd1f-a0e498f692f7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: leann ask [-h] [--llm {simulated,ollama,hf,openai}] [--model MODEL]\n",
            "                 [--host HOST] [--interactive] [--top-k TOP_K]\n",
            "                 [--complexity COMPLEXITY] [--beam-width BEAM_WIDTH]\n",
            "                 [--prune-ratio PRUNE_RATIO] [--recompute | --no-recompute]\n",
            "                 [--pruning-strategy {global,local,proportional}]\n",
            "                 [--thinking-budget {low,medium,high}]\n",
            "                 index_name\n",
            "\n",
            "positional arguments:\n",
            "  index_name            Index name\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --llm {simulated,ollama,hf,openai}\n",
            "                        LLM provider (default: ollama)\n",
            "  --model MODEL         Model name (default: qwen3:8b)\n",
            "  --host HOST\n",
            "  --interactive, -i     Interactive chat mode\n",
            "  --top-k TOP_K         Retrieval count (default: 20)\n",
            "  --complexity COMPLEXITY\n",
            "  --beam-width BEAM_WIDTH\n",
            "  --prune-ratio PRUNE_RATIO\n",
            "  --recompute, --no-recompute\n",
            "                        Enable/disable embedding recomputation during ask\n",
            "                        (default: enabled)\n",
            "  --pruning-strategy {global,local,proportional}\n",
            "  --thinking-budget {low,medium,high}\n",
            "                        Thinking budget for reasoning models\n",
            "                        (low/medium/high). Supported by GPT-Oss:20b and other\n",
            "                        reasoning models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "usage: leann ask [-h] [--llm {simulated,ollama,hf,openai}] [--model MODEL]\n",
        "                 [--host HOST] [--interactive] [--top-k TOP_K]\n",
        "                 [--complexity COMPLEXITY] [--beam-width BEAM_WIDTH]\n",
        "                 [--prune-ratio PRUNE_RATIO] [--recompute | --no-recompute]\n",
        "                 [--pruning-strategy {global,local,proportional}]\n",
        "                 [--thinking-budget {low,medium,high}]\n",
        "                 index_name\n",
        "\n",
        "positional arguments:\n",
        "  index_name            Index name\n",
        "\n",
        "options:\n",
        "  -h, --help            show this help message and exit\n",
        "  --llm {simulated,ollama,hf,openai}\n",
        "                        LLM provider (default: ollama)\n",
        "  --model MODEL         Model name (default: qwen3:8b)\n",
        "  --host HOST\n",
        "  --interactive, -i     Interactive chat mode\n",
        "  --top-k TOP_K         Retrieval count (default: 20)\n",
        "  --complexity COMPLEXITY\n",
        "  --beam-width BEAM_WIDTH\n",
        "  --prune-ratio PRUNE_RATIO\n",
        "  --recompute, --no-recompute\n",
        "                        Enable/disable embedding recomputation during ask\n",
        "                        (default: enabled)\n",
        "  --pruning-strategy {global,local,proportional}\n",
        "  --thinking-budget {low,medium,high}\n",
        "                        Thinking budget for reasoning models\n",
        "                        (low/medium/high). Supported by GPT-Oss:20b and other\n",
        "                        reasoning models."
      ],
      "metadata": {
        "id": "Guc3PT-jBlbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!leann ask mydemo --llm ollama --model gemma3:1b --top-k 1  -i"
      ],
      "metadata": {
        "id": "VLPOjHgwBSLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!leann ask mydemo --llm ollama --model gemma3:1b  -i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bux4e1DIApFy",
        "outputId": "cdb7e6c4-4e41-4489-b92b-f091d1bc4748"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting chat with index 'mydemo'...\n",
            "Using gemma3:1b (ollama)\n",
            "[read_HNSW - CSR NL v4] Reading metadata & CSR indices (manual offset)...\n",
            "[read_HNSW NL v4] Read levels vector, size: 1\n",
            "[read_HNSW NL v4] Reading Compact Storage format indices...\n",
            "[read_HNSW NL v4] Read compact_level_ptr, size: 2\n",
            "[read_HNSW NL v4] Read compact_node_offsets, size: 2\n",
            "[read_HNSW NL v4] Read entry_point: 0, max_level: 0\n",
            "[read_HNSW NL v4] Read storage fourcc: 0x6c6c756e\n",
            "[read_HNSW NL v4 FIX] Detected FileIOReader. Neighbors size field offset: 214\n",
            "[read_HNSW NL v4] Reading neighbors data into memory.\n",
            "[read_HNSW NL v4] Read neighbors data, size: 0\n",
            "[read_HNSW NL v4] Finished reading metadata and CSR indices.\n",
            "INFO: Skipping external storage loading, since is_recompute is true.\n",
            "LEANN Assistant ready! Type 'quit' to exit\n",
            "========================================\n",
            "\n",
            "You: what is python?\n",
            "WARNING:leann.api:  ⚠️  Requested top_k (20) exceeds total documents (1)\n",
            "WARNING:leann.api:  ✅ Auto-adjusted top_k to 1 to match available documents\n",
            "ZmqDistanceComputer initialized: d=768, metric=0\n",
            "LEANN: Based on the provided context, Python is a high-level, interpreted programming language known for its simplicity, readability, versatility, and ease of use. It was created by Guido van Rossum and first released in 1991.\n",
            "\n",
            "You: exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!leann ask mydemo --llm hf --model Qwen/Qwen3-0.6B --top-k 1  -i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgSqB61NBsEk",
        "outputId": "f33874b1-ec6c-4c7b-a45f-4fecba762034"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting chat with index 'mydemo'...\n",
            "Using Qwen/Qwen3-0.6B (hf)\n",
            "[read_HNSW - CSR NL v4] Reading metadata & CSR indices (manual offset)...\n",
            "[read_HNSW NL v4] Read levels vector, size: 1\n",
            "[read_HNSW NL v4] Reading Compact Storage format indices...\n",
            "[read_HNSW NL v4] Read compact_level_ptr, size: 2\n",
            "[read_HNSW NL v4] Read compact_node_offsets, size: 2\n",
            "[read_HNSW NL v4] Read entry_point: 0, max_level: 0\n",
            "[read_HNSW NL v4] Read storage fourcc: 0x6c6c756e\n",
            "[read_HNSW NL v4 FIX] Detected FileIOReader. Neighbors size field offset: 214\n",
            "[read_HNSW NL v4] Reading neighbors data into memory.\n",
            "[read_HNSW NL v4] Read neighbors data, size: 0\n",
            "[read_HNSW NL v4] Finished reading metadata and CSR indices.\n",
            "INFO: Skipping external storage loading, since is_recompute is true.\n",
            "tokenizer_config.json: 9.73kB [00:00, 2.07MB/s]\n",
            "vocab.json: 2.78MB [00:00, 39.8MB/s]\n",
            "merges.txt: 1.67MB [00:00, 86.2MB/s]\n",
            "tokenizer.json: 100% 11.4M/11.4M [00:00<00:00, 23.7MB/s]\n",
            "config.json: 100% 726/726 [00:00<00:00, 4.31MB/s]\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "2025-09-25 22:41:16.404505: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1758840076.437379   22132 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1758840076.444250   22132 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1758840076.460881   22132 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758840076.460931   22132 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758840076.460936   22132 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758840076.460940   22132 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-25 22:41:16.466011: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "model.safetensors: 100% 1.50G/1.50G [00:23<00:00, 64.6MB/s]\n",
            "generation_config.json: 100% 239/239 [00:00<00:00, 1.31MB/s]\n",
            "LEANN Assistant ready! Type 'quit' to exit\n",
            "========================================\n",
            "\n",
            "You: what is python?\n",
            "ZmqDistanceComputer initialized: d=768, metric=0\n",
            "kwargs in HF:  {}\n",
            "LEANN: <think>\n",
            "\n",
            "</think>\n",
            "\n",
            "Python is a high-level, interpreted programming language known for its simplicity, readability, and versatility. Created by Guido van Rossum and first released in 1991, Python emphasizes code readability and allows developers to express concepts in fewer lines of code compared to many other programming languages.\n",
            "\n",
            "You: exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    }
  ]
}