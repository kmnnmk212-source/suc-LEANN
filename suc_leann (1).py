# -*- coding: utf-8 -*-
"""suc_leann.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vyHw3nCwV3QmUGjnoINBT16gCi2OvZRb
"""











/content/leann/data/PrideandPrejudice.txt
النص

Title: Pride and Prejudice

Author: Jane Austen

Release date: June 1, 1998 [eBook #1342]
                Most recently updated: October 29, 2024

Language: English

"""### شغاله"""

!leann build my-docs --docs ./data --force

"""### شغالة"""

!leann search my-docs "author"

"""# الصيغة تللك تعمل **جيدا**"""

!leann ask /content/leann/.leann/indexes/my-docs --model llama3.2:1b --interactive







"""### شغال"""

!leann build my-notes --docs ./data --embedding-mode ollama --embedding-model nomic-embed-text:latest

"""### شغاله"""

!leann ask my-notes --llm ollama  --model llama3.2:1b -i



"""### شغال"""

!leann build my-index --force --no-recompute --no-compact


from leann import LeannSearcher

searcher = LeannSearcher("/content/leann/.leann/indexes")
results = searcher.search("What is the author’s name", top_k=10)

!leann ask /content/leann/.leann/indexes/my-docs --model llama3.2:1b --interactive


Starting chat with index '/content/leann/.leann/indexes/my-docs'...
Using llama3.2:1b (ollama)
[read_HNSW - CSR NL v4] Reading metadata & CSR indices (manual offset)...
[read_HNSW NL v4] Read levels vector, size: 1
[read_HNSW NL v4] Reading Compact Storage format indices...
[read_HNSW NL v4] Read compact_level_ptr, size: 2
[read_HNSW NL v4] Read compact_node_offsets, size: 2
[read_HNSW NL v4] Read entry_point: 0, max_level: 0
[read_HNSW NL v4] Read storage fourcc: 0x6c6c756e
[read_HNSW NL v4 FIX] Detected FileIOReader. Neighbors size field offset: 214
[read_HNSW NL v4] Reading neighbors data into memory.
[read_HNSW NL v4] Read neighbors data, size: 0
[read_HNSW NL v4] Finished reading metadata and CSR indices.
INFO: Skipping external storage loading, since is_recompute is true.
LEANN Assistant ready! Type 'quit' to exit
========================================

You: What is the author’s name
WARNING:leann.api:  ⚠️  Requested top_k (20) exceeds total documents (1)
WARNING:leann.api:  ✅ Auto-adjusted top_k to 1 to match available documents
ZmqDistanceComputer initialized: d=768, metric=0
LEANN: Based on the provided context, I can confidently answer that the author's name is Jane Austen. The fact that it's an eBook with a release date (1998) and updates (2024), along with being part of a larger literary work (Pride and Prejudice), strongly suggests that it is indeed written by Jane Austen.

You: Show me the existing text.
WARNING:leann.api:  ⚠️  Requested top_k (20) exceeds total documents (1)
WARNING:leann.api:  ✅ Auto-adjusted top_k to 1 to match available documents
ZmqDistanceComputer initialized: d=768, metric=0
LEANN: Based on the provided context, I will attempt to display the existing text of "Pride and Prejudice" by Jane Austen:

"Not for the last time, Miss Bingley has been the object of my jealousy; but at present I am not so much affected by her beauty as by her good sense. Her father is a man of some property, but he is not in every respect advantageous to her family; though his abilities are better than his heart, and many people consider him great. His sister Jane is very pretty, and an excellent musician; she has a tolerable voice, which can scarce be expected to captivate the heart, but it may influence it. Her character is of a middle sort; not handsome, but not ugly; serious, reserved, and not very attractive; though her personal beauty, as I said before, is quite lost on me."

Please note that this is an excerpt from the 1998 eBook edition of "Pride and Prejudice" with the most recent update being October 29, 2024.

You: what is Release date?
WARNING:leann.api:  ⚠️  Requested top_k (20) exceeds total documents (1)
WARNING:leann.api:  ✅ Auto-adjusted top_k to 1 to match available documents
ZmqDistanceComputer initialized: d=768, metric=0
LEANN: Based on the provided context, I'm going to take a close look at the information.

The release date mentioned in the question is June 1, 1998.

However, according to the text, the book was "most recently updated" on October 29, 2024. This implies that there have been changes or updates made to the text since the original publication of the book, specifically after January 1, 2025 (not 2024).

You: exit
Goodbye!

النص
Title: Pride and Prejudice

Author: Jane Austen

Release date: June 1, 1998 [eBook #1342]
                Most recently updated: October 29, 2024

Language: English


الصيغة دى تعمل باقى الصيغ لاتعمل



















"""https://github.com/yichuan-w/LEANN/tree/main"""

# تثبيت المكتبات الأساسية لـ LEANN
!uv pip install leann-core leann-backend-hnsw --no-deps
!uv pip install leann --no-deps

# تثبيت مكتبة pypdf لقراءة ملفات PDF
!pip install pypdf

import os
from pathlib import Path
from google.colab import files
from pypdf import PdfReader
import logging

# إعدادات لتسجيل معلومات أكثر تفصيلاً
os.environ["LEANN_LOG_LEVEL"] = "INFO"
logging.basicConfig(level=logging.INFO)

# تحديد مسار لحفظ الفهرس
INDEX_DIR = Path("./").resolve()
INDEX_PATH = str(INDEX_DIR / "demo.leann")

print("تم تجهيز الإعدادات بنجاح.")

print("الرجاء اختيار ملف PDF لرفعه...")
uploaded = files.upload()

# التأكد من أنه تم رفع ملف واحد فقط واستخلاص اسمه
if len(uploaded) == 0:
    print("لم يتم رفع أي ملف.")
elif len(uploaded) > 1:
    print("الرجاء رفع ملف واحد فقط.")
else:
    pdf_name = next(iter(uploaded))
    print(f"\nتم رفع الملف '{pdf_name}' بنجاح.")

if 'pdf_name' in locals():
    print(f"جاري استخلاص النص من '{pdf_name}'...")

    # قائمة لتخزين أجزاء النص
    text_chunks = []

    try:
        reader = PdfReader(pdf_name)
        full_text = ""
        for page in reader.pages:
            full_text += page.extract_text() + "\n"

        # تقسيم النص الكامل إلى أجزاء بناءً على الفقرات (سطرين فارغين)
        text_chunks = [chunk.strip() for chunk in full_text.split('\n\n') if chunk.strip()]

        print(f"تم تقسيم النص إلى {len(text_chunks)} جزء/فقرة.")
    except Exception as e:
        print(f"حدث خطأ أثناء قراءة الملف: {e}")
else:
    print("الرجاء تشغيل خلية رفع الملف أولاً.")

from leann.api import LeannBuilder

if text_chunks:
    print("جاري بناء الفهرس من محتوى الـ PDF...")
    builder = LeannBuilder(backend_name="hnsw")

    # إضافة كل جزء نصي إلى الباني
    for chunk in text_chunks:
        builder.add_text(chunk)

    # بناء وحفظ الفهرس في المسار المحدد
    builder.build_index(INDEX_PATH)
    print(f"تم بناء الفهرس بنجاح وتم حفظه في: {INDEX_PATH}")
else:
    print("لا يوجد نص لبناء الفهرس. الرجاء التأكد من أن ملف الـ PDF يحتوي على نص وأن الخلية السابقة عملت بنجاح.")

from leann.api import LeannSearcher

if os.path.exists(INDEX_PATH):
    # قم بتغيير النص أدناه للبحث عن أي شيء في المستند الخاص بك
    search_query = "Climate Change"

    print(f"جاري البحث عن: '{search_query}'...")
    searcher = LeannSearcher(INDEX_PATH)
    results = searcher.search(search_query, top_k=2)

    # عرض النتائج
    for result in results:
        print(f"Score: {result.score:.4f}")
        print(f"Text: {result.text}\n")
else:
    print("ملف الفهرس غير موجود. الرجاء تشغيل خلية بناء الفهرس أولاً.")

Understanding Climate Change

from leann.api import LeannChat

if os.path.exists(INDEX_PATH):
    llm_config = {
        "type": "hf",
        "model": "Qwen/Qwen3-0.6B",
    }

    chat = LeannChat(index_path=INDEX_PATH, llm_config=llm_config)

    # قم بتغيير السؤال أدناه ليناسب محتوى ملف الـ PDF الذي رفعته
    question = "what is Climate Change?"

    print(f"طرح السؤال: {question}")

    response = chat.ask(
        question,
        top_k=3,  # استخدام 3 نتائج من البحث لتعزيز الإجابة
        llm_kwargs={"max_tokens": 256},
    )

    print("\n--- الإجابة ---")
    print(response)
else:
    print("ملف الفهرس غير موجود. الرجاء تشغيل خلية بناء الفهرس أولاً.")







# ===================================================================
# الخطوة 1: تثبيت جميع المكتبات المطلوبة
# ===================================================================
print("--- الخطوة 1: جاري تثبيت المكتبات... ---")
# استخدام quiet=True لتقليل المخرجات غير الضرورية
!pip install uv > /dev/null
!uv pip install leann-core leann-backend-hnsw --no-deps --quiet
!uv pip install leann --no-deps --quiet
!pip install pypdf --quiet
print("=> تم تثبيت المكتبات بنجاح.\n")


# ===================================================================
# الخطوة 2: استيراد المكتبات والإعدادات الأولية
# ===================================================================
print("--- الخطوة 2: جاري إعداد البيئة... ---")
import os
import logging
from pathlib import Path
from google.colab import files
from pypdf import PdfReader
from leann.api import LeannBuilder, LeannSearcher, LeannChat

# إعدادات لتسجيل معلومات أكثر تفصيلاً
os.environ["LEANN_LOG_LEVEL"] = "INFO"
logging.basicConfig(level=logging.INFO)

# تحديد مسار لحفظ الفهرس
INDEX_DIR = Path("./").resolve()
INDEX_PATH = str(INDEX_DIR / "demo.leann")

# متغيرات لتخزين اسم الملف والنص
pdf_name = None
text_chunks = []
print("=> تم تجهيز الإعدادات بنجاح.\n")


# ===================================================================
# الخطوة 3: رفع ملف الـ PDF
# ===================================================================
print("--- الخطوة 3: رفع ملف الـ PDF ---")
print("الرجاء اختيار ملف PDF من جهازك...")
try:
    # حذف الفهرس القديم إذا كان موجودًا لضمان البدء من جديد
    if os.path.exists(INDEX_PATH):
        os.remove(INDEX_PATH)

    uploaded = files.upload()

    if uploaded:
        pdf_name = next(iter(uploaded))
        print(f"\n=> تم رفع الملف '{pdf_name}' بنجاح.\n")
    else:
        print("\n!! لم يتم اختيار أي ملف. توقف التنفيذ. !!")
except Exception as e:
    print(f"\n!! حدث خطأ أثناء رفع الملف: {e} !!")


# ===================================================================
# الخطوة 4: استخلاص النص من الـ PDF وتقسيمه
# ===================================================================
if pdf_name:
    print(f"--- الخطوة 4: جاري استخلاص النص من '{pdf_name}'... ---")
    try:
        reader = PdfReader(pdf_name)
        full_text = ""
        for page in reader.pages:
            page_text = page.extract_text()
            if page_text:
                full_text += page_text + "\n"

        # تقسيم النص الكامل إلى فقرات
        text_chunks = [chunk.strip() for chunk in full_text.split('\n\n') if chunk.strip()]

        if text_chunks:
            print(f"=> تم تقسيم النص إلى {len(text_chunks)} جزء/فقرة.\n")
        else:
            print("\n!! لم يتم العثور على نص في ملف الـ PDF. قد يكون الملف عبارة عن صور. !!")
    except Exception as e:
        print(f"\n!! حدث خطأ أثناء قراءة الملف: {e} !!")


# ===================================================================
# الخطوة 5: بناء الفهرس (Index)
# ===================================================================
if text_chunks:
    print("--- الخطوة 5: جاري بناء الفهرس من محتوى الـ PDF... ---")
    builder = LeannBuilder(backend_name="hnsw")
    for chunk in text_chunks:
        builder.add_text(chunk)
    builder.build_index(INDEX_PATH)
    print(f"=> تم بناء الفهرس بنجاح وتم حفظه في: {INDEX_PATH}\n")


# ===================================================================
# الخطوة 6: البحث في محتوى الملف
# ===================================================================
# التحقق من أن الفهرس تم إنشاؤه بنجاح
if os.path.exists(INDEX_PATH):
    print("--- الخطوة 6: تجربة البحث في المستند ---")

    # !!! هام: قم بتغيير النص أدناه للبحث عن أي شيء في المستند الخاص بك !!!
    search_query = "Climate Change"

    print(f"جاري البحث عن: '{search_query}'...")
    searcher = LeannSearcher(INDEX_PATH)
    results = searcher.search(search_query, top_k=2)

    print("\n--- نتائج البحث ---")
    if results:
        for result in results:
            print(f"Score: {result.score:.4f}")
            print(f"Text: {result.text}\n")
    else:
        print("لم يتم العثور على نتائج.\n")


# ===================================================================
# الخطوة 7: الدردشة مع المستند (RAG)
# ===================================================================
# التحقق مرة أخرى قبل تشغيل الدردشة
if os.path.exists(INDEX_PATH):
    print("--- الخطوة 7: الدردشة مع المستند (RAG) ---")
    llm_config = {
        "type": "hf",
        "model": "Qwen/Qwen3-0.6B",
    }
    chat = LeannChat(index_path=INDEX_PATH, llm_config=llm_config)

    # !!! هام: قم بتغيير السؤال أدناه ليناسب محتوى ملف الـ PDF الذي رفعته !!!
    question = "what is Climate Change?"

    print(f"طرح السؤال: {question}\n")

    response = chat.ask(
        question,
        top_k=3,
        llm_kwargs={"max_tokens": 256},
    )

    print("\n--- الإجابة النهائية من النموذج ---")
    print(response)

!uv pip install leann

!leann --help

===================================================================
# الخطوة 1: تثبيت جميع المكتبات المطلوبة (بما في ذلك langchain)
# ===================================================================
print("--- الخطوة 1: جاري تثبيت المكتبات... ---")
!pip install uv > /dev/null
!uv pip install leann-core leann-backend-hnsw --no-deps --quiet
!uv pip install leann --no-deps --quiet
!pip install pypdf langchain --quiet
print("=> تم تثبيت المكتبات بنجاح.\n")

#


# ===================================================================
# الخطوة 2: استيراد المكتبات والإعدادات الأولية
# ===================================================================
print("--- الخطوة 2: جاري إعداد البيئة... ---")
import os
import logging
from pathlib import Path
from google.colab import files
from pypdf import PdfReader
from leann.api import LeannBuilder, LeannSearcher, LeannChat
# *** جديد: استيراد مقسم النصوص من langchain ***
from langchain.text_splitter import RecursiveCharacterTextSplitter

os.environ["LEANN_LOG_LEVEL"] = "INFO"
logging.basicConfig(level=logging.INFO)
INDEX_DIR = Path("./").resolve()
INDEX_PATH = str(INDEX_DIR / "demo.leann")

pdf_name = None
text_chunks = []
print("=> تم تجهيز الإعدادات بنجاح.\n")


# ===================================================================
# الخطوة 3: رفع ملف الـ PDF
# ===================================================================
print("--- الخطوة 3: رفع ملف الـ PDF ---")
print("الرجاء اختيار ملف PDF من جهازك...")
try:
    if os.path.exists(INDEX_PATH):
        os.remove(INDEX_PATH)
    uploaded = files.upload()
    if uploaded:
        pdf_name = next(iter(uploaded))
        print(f"\n=> تم رفع الملف '{pdf_name}' بنجاح.\n")
    else:
        print("\n!! لم يتم اختيار أي ملف. توقف التنفيذ. !!")
except Exception as e:
    print(f"\n!! حدث خطأ أثناء رفع الملف: {e} !!")


# ===================================================================
# الخطوة 4: استخلاص النص وتقسيمه بطريقة احترافية
# ===================================================================
if pdf_name:
    print(f"--- الخطوة 4: جاري استخلاص وتقسيم النص من '{pdf_name}'... ---")
    try:
        reader = PdfReader(pdf_name)
        full_text = ""
        for page in reader.pages:
            page_text = page.extract_text()
            if page_text:
                full_text += page_text + "\n"

        # *** جديد: استخدام مقسم النصوص الاحترافي ***
        # نقسم النص إلى أجزاء حجم كل منها 1000 حرف، مع تداخل 150 حرف لضمان عدم فقدان السياق
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=150,
            length_function=len
        )
        text_chunks = text_splitter.split_text(full_text)

        if text_chunks:
            print(f"=> تم تقسيم النص بنجاح إلى {len(text_chunks)} جزء.\n")
        else:
            print("\n!! لم يتم العثور على نص في ملف الـ PDF. !!")
    except Exception as e:
        print(f"\n!! حدث خطأ أثناء قراءة الملف: {e} !!")


# ===================================================================
# الخطوة 5: بناء الفهرس (Index)
# ===================================================================
if text_chunks:
    print("--- الخطوة 5: جاري بناء الفهرس من محتوى الـ PDF... ---")
    builder = LeannBuilder(backend_name="hnsw")
    for chunk in text_chunks:
        builder.add_text(chunk)
    builder.build_index(INDEX_PATH)
    print(f"=> تم بناء الفهرس بنجاح وتم حفظه في: {INDEX_PATH}\n")


# ===================================================================
# الخطوة 6: البحث في محتوى الملف
# ===================================================================
if os.path.exists(INDEX_PATH):
    print("--- الخطوة 6: تجربة البحث في المستند ---")
    search_query = "Climate Change"
    print(f"جاري البحث عن: '{search_query}'...")
    searcher = LeannSearcher(INDEX_PATH)
    results = searcher.search(search_query, top_k=3)

    print("\n--- أفضل 3 نتائج بحث ---")
    if results:
        for i, result in enumerate(results):
            print(f"--- نتيجة {i+1} (Score: {result.score:.4f}) ---")
            print(f"{result.text}\n")
    else:
        print("لم يتم العثور على نتائج.\n")


# ===================================================================
# الخطوة 7: الدردشة مع المستند (RAG)
# ===================================================================
if os.path.exists(INDEX_PATH):
    print("--- الخطوة 7: الدردشة مع المستند (RAG) ---")
    # *** رسالة توضيحية جديدة ***
    print("سيتم الآن تحميل نموذج اللغة. قد تستغرق هذه العملية بضع دقائق في المرة الأولى، الرجاء الانتظار...")

    llm_config = {
        "type": "hf",
        "model": "Qwen/Qwen3-0.6B",
    }
    chat = LeannChat(index_path=INDEX_PATH, llm_config=llm_config)

    question = "what is Climate Change based on the provided document?"
    print(f"\nطرح السؤال: {question}\n")

    response = chat.ask(
        question,
        top_k=3,
        llm_kwargs={"max_tokens": 512}, # زيادة الحد الأقصى للكلمات لإجابة أكثر تفصيلاً
    )

    print("\n✅ --- الإجابة النهائية من النموذج --- ✅")
    print(response)

if os.path.exists(INDEX_PATH):
    print("--- الخطوة 7: الدردشة مع المستند (RAG) ---")
    # *** رسالة توضيحية جديدة ***
    print("سيتم الآن تحميل نموذج اللغة. قد تستغرق هذه العملية بضع دقائق في المرة الأولى، الرجاء الانتظار...")

    llm_config = {
        "type": "hf",
        "model": "Qwen/Qwen3-0.6B",
    }
    chat = LeannChat(index_path=INDEX_PATH, llm_config=llm_config)

    question = "what is Climate Change based on the provided document?"
    print(f"\nطرح السؤال: {question}\n")

    response = chat.ask(
        question,
        top_k=3,
        llm_kwargs={"max_tokens": 512}, # زيادة الحد الأقصى للكلمات لإجابة أكثر تفصيلاً
    )

    print("\n✅ --- الإجابة النهائية من النموذج --- ✅")
    print(response)

# ===================================================================
# الخطوة 1: تثبيت جميع المكتبات المطلوبة
# ===================================================================
print("--- الخطوة 1: جاري تثبيت المكتبات... ---")
!pip install uv > /dev/null
!uv pip install leann-core leann-backend-hnsw --no-deps --quiet
!uv pip install leann --no-deps --quiet
!pip install pypdf langchain sentence-transformers --quiet
print("=> تم تثبيت المكتبات بنجاح.\n")


# ===================================================================
# الخطوة 2: استيراد المكتبات والإعدادات الأولية
# ===================================================================
print("--- الخطوة 2: جاري إعداد البيئة... ---")
import os
import logging
from pathlib import Path
from google.colab import files
from pypdf import PdfReader
from leann.api import LeannBuilder, LeannSearcher, LeannChat
from langchain.text_splitter import RecursiveCharacterTextSplitter

os.environ["LEANN_LOG_LEVEL"] = "INFO"
logging.basicConfig(level=logging.INFO)
INDEX_DIR = Path("./").resolve()
INDEX_PATH = str(INDEX_DIR / "demo.leann")

pdf_name = None
text_chunks = []
print("=> تم تجهيز الإعدادات بنجاح.\n")


# ===================================================================
# الخطوة 3: رفع ملف الـ PDF
# ===================================================================
print("--- الخطوة 3: رفع ملف الـ PDF ---")
print("الرجاء اختيار ملف PDF من جهازك...")
try:
    if os.path.exists(INDEX_PATH):
        os.remove(INDEX_PATH)
    uploaded = files.upload()
    if uploaded:
        pdf_name = next(iter(uploaded))
        print(f"\n=> تم رفع الملف '{pdf_name}' بنجاح.\n")
    else:
        print("\n!! لم يتم اختيار أي ملف. توقف التنفيذ. !!")
except Exception as e:
    print(f"\n!! حدث خطأ أثناء رفع الملف: {e} !!")


# ===================================================================
# الخطوة 4: استخلاص النص وتقسيمه
# ===================================================================
if pdf_name:
    print(f"--- الخطوة 4: جاري استخلاص وتقسيم النص من '{pdf_name}'... ---")
    try:
        reader = PdfReader(pdf_name)
        full_text = ""
        for page in reader.pages:
            page_text = page.extract_text()
            if page_text:
                full_text += page_text + "\n"

        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=150,
            length_function=len
        )
        text_chunks = text_splitter.split_text(full_text)

        if text_chunks:
            print(f"=> تم تقسيم النص بنجاح إلى {len(text_chunks)} جزء.\n")
        else:
            print("\n!! لم يتم العثور على نص في ملف الـ PDF. !!")
    except Exception as e:
        print(f"\n!! حدث خطأ أثناء قراءة الملف: {e} !!")


# ===================================================================
# الخطوة 5: بناء الفهرس باستخدام نموذج خفيف
# ===================================================================
if text_chunks:
    print("--- الخطوة 5: جاري بناء الفهرس باستخدام نموذج خفيف ومناسب للمعالج... ---")

    # *** التعديل الرئيسي: تحديد نموذج خفيف ومناسب للمعالج ***
    builder = LeannBuilder(
        backend_name="hnsw",
        embedding_model_name="sentence-transformers/all-MiniLM-L6-v2"
    )

    for chunk in text_chunks:
        builder.add_text(chunk)
    builder.build_index(INDEX_PATH)
    print(f"=> تم بناء الفهرس بنجاح وتم حفظه في: {INDEX_PATH}\n")


# ===================================================================
# الخطوة 6: البحث في محتوى الملف
# ===================================================================
if os.path.exists(INDEX_PATH):
    print("--- الخطوة 6: تجربة البحث في المستند ---")
    search_query = "Climate Change"
    print(f"جاري البحث عن: '{search_query}'...")
    searcher = LeannSearcher(INDEX_PATH)
    results = searcher.search(search_query, top_k=3)

    print("\n--- أفضل 3 نتائج بحث ---")
    if results:
        for i, result in enumerate(results):
            print(f"--- نتيجة {i+1} (Score: {result.score:.4f}) ---")
            print(f"{result.text}\n")
    else:
        print("لم يتم العثور على نتائج.\n")


# ===================================================================
# الخطوة 7: الدردشة مع المستند (RAG)
# ===================================================================
if os.path.exists(INDEX_PATH):
    print("--- الخطوة 7: الدردشة مع المستند (RAG) ---")
    print("سيتم الآن تحميل نموذج اللغة. قد تستغرق هذه العملية بضع دقائق، الرجاء الانتظار...")

    llm_config = {
        "type": "hf",
        "model": "Qwen/Qwen3-0.6B",
    }
    chat = LeannChat(index_path=INDEX_PATH, llm_config=llm_config)

    question = "what is Climate Change based on the provided document?"
    print(f"\nطرح السؤال: {question}\n")

    response = chat.ask(
        question,
        top_k=3,
        llm_kwargs={"max_tokens": 512},
    )

    print("\n✅ --- الإجابة النهائية من النموذج --- ✅")
    print(response)

!git clone https://github.com/yichuan-w/LEANN.git leann

# Commented out IPython magic to ensure Python compatibility.
# %cd leann

!python examples

!leann search /content/leann/Understanding_Climate_Change.pdf "ما هي الفكرة الرئيسية في الفصل الثالث؟" --top-k 3

!python /content/leann/apps/base_rag_example.py

!uv pip install leann

!uv pip install ollama

curl -fsSL https://ollama.com/install.sh | sh
nohup ollama serve &
ollama pull llama3:8b
ollama list

!curl -fsSL https://ollama.com/install.sh | sh

!nohup ollama serve &
!ollama pull llama3.2:1b



!python -m apps.document_rag --query "What are the main techniques LEANN explores?"

/content/leann/apps/base_rag_example.py

!python -m apps.base_rag_example -help

!python -m apps.base_rag_example --embedding-model sentence-transformers/all-mpnet-base-v2 --llm-model Qwen/Qwen3-0.6B  --query "What are the main techniques LEANN explores?"

!ollama list

import os
from leann import Client

def build_index(index_name: str, docs_path: str):
    """
    يبني الـ index من ملف (أو مجلد) المستندات.
    """
    client = Client()
    # إذا كان الـ index موجود يمكن استخدام force=True لإعادة البناء
    client.build(index_name, docs=[docs_path], force=True)
    print(f"تم بناء الفهرس: {index_name}")

def ask_question(index_name: str, question: str, llm: str = "openai", model: str = "gpt-4o-mini", top_k: int = 5):
    """
    يطرح سؤالًا على الـ index باستخدام LLM مختار.
    """
    client = Client()
    resp = client.ask(
        index_name,
        query=question,
        llm=llm,
        model=model,
        top_k=top_k
    )
    return resp.answer, resp

def main():
    # --- الإعدادات (عدّلها حسب الكتاب وبيئتك) ---
    index_name = "my_book_index"
    book_path = "book.pdf"  # أو إذا استخدمت OCR، مثلاً "book_ocr.pdf"
    # مفتاح OpenAI (إذا تستخدم واجهة OpenAI)
    os.environ["OPENAI_API_KEY"] = "ضع_مفتاحك_هنا"

    # 1. بناء الفهرس
    build_index(index_name, book_path)

    # 2. طرح أسئلة
    question = "ما هي الفكرة الأساسية في الفصل الثالث؟"
    answer, full_resp = ask_question(index_name, question)
    print("السؤال:", question)
    print("الإجابة:", answer)

    # يمكنك طرح أسئلة إضافية تكراريا
    q2 = "ماذا تعلمت عن موضوع X في الكتاب؟"
    ans2, resp2 = ask_question(index_name, q2)
    print("السؤال:", q2)
    print("الإجابة:", ans2)

    # إذا تريد عرض التفاصيل (المقاطع المسترجعة، الأوزان، إلخ)
    print("تفاصيل الاسترجاع:", full_resp)

if __name__ == "__main__":
    main()

from leann import Client

def build_index(index_name: str, docs_path: str):
    client = Client()
    # إذا كان الفهرس موجودًا فاستعمل force=True لإعادة البناء
    client.build(index_name, docs=[docs_path], force=True)
    print(f"تم بناء الفهرس: {index_name}")

def ask_with_ollama(index_name: str, question: str, top_k: int = 5):
    client = Client()
    resp = client.ask(
        index_name,
        query=question,
        llm="ollama",
        model="llama3.2:1b",
        top_k=top_k
    )
    return resp.answer, resp

def main():
    index_name = "my_book_idx"
    book_path = "/content/leann/Understanding_Climate_Change.pdf"  # أو المسار إلى الكتاب الذي تريد استخدامه

    # بناء الفهرس أولًا
    build_index(index_name, book_path)

    # الآن اسأل سؤالًا
    q = "What is the main idea in the book?"
    answer, resp = ask_with_ollama(index_name, q)
    print("السؤال:", q)
    print("الإجابة:", answer)

    # إذا أردت مزيد من التفاصيل عن المقاطع المستخدمة
    print("تفاصيل:", resp)

if __name__ == "__main__":
    main()

!python -m apps.document_rag --query "What techniques does LEANN use?"

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/leann

!python -m apps.document_rag --query "What techniques does LEANN use?"

!ollama pull nomic-embed-text

!ollama list

!python -m apps.document_rag --query "What techniques does LEANN use?"

!export LEANN_OLLAMA_HOST="http://localhost:11434"

!leann ask /content/leann/Understanding_Climate_Change.pdf \
  --llm ollama \
  --llm-model llama3.2 \
  --host http://192.168.1.101:11434

from leann.api import LeannBuilder

builder = LeannBuilder(
    backend_name="hnsw",
    embedding_model="nomic-embed-text:latest",
    embedding_options={
        "base_url": "http://192.168.1.101:11434/v1",
    },
)
builder.build_index("/content/leann", chunks)

!python apps/document_rag.py --query "What are the main techniques LEANN explores?" \
  --index-dir hnswbuild --backend hnsw \
  --llm ollama --llm-model llama3.2:1b --thinking-budget high

!pip install git+https://github.com/yichuan-w/LEANN.git

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/leann

!leann build \
  --add-file "/content/leann/Understanding_Climate_Change.pdf" \
  --index-path "./my_book.leann" \
  --backend "hnsw" \
  --embedding-model-name "sentence-transformers/all-MiniLM-L6-v2" \
  --chunk-size 1000 \
  --chunk-overlap 150

!leann build leann [-h] {build,search,ask,list,remove}

!leann -h

"""usage: leann [-h] {build,search,ask,list,remove} ...

The smallest vector index in the world. RAG Everything with LEANN!

positional arguments:
  {build,search,ask,list,remove}
                        Available commands
    build               Build document index
    search              Search documents
    ask                 Ask questions
    list                List all indexes
    remove              Remove an index

options:
  -h, --help            show this help message and exit

Examples:
  leann build my-docs --docs ./documents                                  # Build index from directory
  leann build my-code --docs ./src ./tests ./config                      # Build index from multiple directories
  leann build my-files --docs ./file1.py ./file2.txt ./docs/             # Build index from files and directories
  leann build my-mixed --docs ./readme.md ./src/ ./config.json           # Build index from mixed files/dirs
  leann build my-ppts --docs ./ --file-types .pptx,.pdf                  # Index only PowerPoint and PDF files
  leann search my-docs "query"                                           # Search in my-docs index
  leann ask my-docs "question"                                           # Ask my-docs index
  leann list                                                             # List all stored indexes
  leann remove my-docs

### شغاله
"""

!leann build my-docs --docs ./data --force

!rm -rf /content/leann/.leann/indexes/my-docs



!leann build my-ppts --docs ./ --file-types .pptx,.pdf

! leann ask my-docs "What is the author's name as it appears in the context?"

"""### شغالة"""

!leann search my-docs "author"

!python apps/document_rag.py --query "What are the main techniques LEANN explores?" \
  --index-dir hnswbuild --backend hnsw \
  --llm ollama --llm-model gpt-oss:20b --thinking-budget high

!leann build \
  --add-file "/path/to/your/book.pdf" \
  --index-path "./my_book.leann" \
  --backend "hnsw" \
  --embedding-model-name "sentence-transformers/all-MiniLM-L6-v2" \
  --chunk-size 1000 \
  --chunk-overlap 150

!leann ask "What is the main theme of the story?" \
  --index-path "./my_book.leann" \
  --llm-type "hf" \
  --llm-model "Qwen/Qwen3-0.6B" \
  --top-k 3





!leann build my-book-index \
  --docs "/content/leann/Understanding_Climate_Change.pdf" \
  --embedding-model-name "sentence-transformers/all-MiniLM-L6-v2" \
  --chunk-size 1000 \
  --chunk-overlap 150

!leann ask /content/leann/.leann/indexes/my-docs "What is the author's name as it appears in the context?" \
  --llm-model "Qwen/Qwen3-0.6B" \
  --top-k 3

!!leann ask my-docs "What is the author's name as it appears in the context?" \
  --llm-model "Qwen/Qwen3-0.6B" \
  --embedding-mode ollama --embedding-model nomic-embed-text \
  --top-k 3

!python -m apps.document_rag --query "What techniques does LEANN use?" --llm ollama --llm-model gpt-oss:20b

!leann ask my-docs "author"

!leann [-h] {build,search,ask,list,remove}

!leann -h ask

!leann list

!ollama list

!leann ask my-docs "What is the author's name as it appears in the context?" --llm ollama --llm-model llama3.2:1b --embedding-model sentence-transformers/all-MiniLM-L6-v2

!python apps/document_rag.py --query "What are the main techniques LEANN explores?" \
  --index-dir hnswbuild --backend hnsw \
  --llm ollama --llm-model llama3.2:1b --thinking-budget high

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/leann

!leann ask my-docs \
  --llm ollama \
  --llm-model llama3.2:1b \
  --query "What is the author's name as it appears in the context??"

!export LEANN_OLLAMA_HOST="http://localhost:11434"

!ollama list

"""https://github.com/yichuan-w/LEANN/blob/main/docs/configuration-guide.md"""

!leann ask my-docs--query "What techniques does LEANN use?" --llm ollama --llm-model llama3.2:1b --embedding-mode ollama --embedding-model nomic-embed-text:latest

!leann ask -help

!leann ask /content/leann/.leann/indexes/my-docs --llm ollama --model llama3.2:1b --query "What is the author's name as it appears in the context?"

!leann ask /content/leann/.leann/indexes/my-docs --model llama3.2:1b -- query "What is the author's name as it appears in the context?"

!leann ask /content/leann/.leann/indexes/my-docs --model llama3.2:1b --query "What is the author’s name in the retrieved context?" --top-k 5

!leann ask /content/leann/.leann/indexes/my-docs --model llama3.2:1b --query "What is the author’s name as shown in the relevant passages?" --top-k 3 --show-passages

!leann ask /content/leann/.leann/indexes/my-docs "What is the author’s name as it appears in the context?"

!leann ask /content/leann/.leann/indexes/my-docs --model llama3.2:1b "What is the author’s name as it appears in the context?"

!leann ask /content/leann/.leann/indexes/my-docs "What is the author’s name as it appears in the context?" --model llama3.2:1b

"""# الصيغة تللك تعمل **جيدا**"""

!leann ask /content/leann/.leann/indexes/my-docs --model llama3.2:1b --interactive

/content/leann/data/PrideandPrejudice.txt
/content/leann/.leann/indexes/my-docs

!leann ask /content/leann/.leann/indexes/my-docs --model llama3.2:1b --interactive


Starting chat with index '/content/leann/.leann/indexes/my-docs'...
Using llama3.2:1b (ollama)
[read_HNSW - CSR NL v4] Reading metadata & CSR indices (manual offset)...
[read_HNSW NL v4] Read levels vector, size: 1
[read_HNSW NL v4] Reading Compact Storage format indices...
[read_HNSW NL v4] Read compact_level_ptr, size: 2
[read_HNSW NL v4] Read compact_node_offsets, size: 2
[read_HNSW NL v4] Read entry_point: 0, max_level: 0
[read_HNSW NL v4] Read storage fourcc: 0x6c6c756e
[read_HNSW NL v4 FIX] Detected FileIOReader. Neighbors size field offset: 214
[read_HNSW NL v4] Reading neighbors data into memory.
[read_HNSW NL v4] Read neighbors data, size: 0
[read_HNSW NL v4] Finished reading metadata and CSR indices.
INFO: Skipping external storage loading, since is_recompute is true.
LEANN Assistant ready! Type 'quit' to exit
========================================

You: What is the author’s name
WARNING:leann.api:  ⚠️  Requested top_k (20) exceeds total documents (1)
WARNING:leann.api:  ✅ Auto-adjusted top_k to 1 to match available documents
ZmqDistanceComputer initialized: d=768, metric=0
LEANN: Based on the provided context, I can confidently answer that the author's name is Jane Austen. The fact that it's an eBook with a release date (1998) and updates (2024), along with being part of a larger literary work (Pride and Prejudice), strongly suggests that it is indeed written by Jane Austen.

You: Show me the existing text.
WARNING:leann.api:  ⚠️  Requested top_k (20) exceeds total documents (1)
WARNING:leann.api:  ✅ Auto-adjusted top_k to 1 to match available documents
ZmqDistanceComputer initialized: d=768, metric=0
LEANN: Based on the provided context, I will attempt to display the existing text of "Pride and Prejudice" by Jane Austen:

"Not for the last time, Miss Bingley has been the object of my jealousy; but at present I am not so much affected by her beauty as by her good sense. Her father is a man of some property, but he is not in every respect advantageous to her family; though his abilities are better than his heart, and many people consider him great. His sister Jane is very pretty, and an excellent musician; she has a tolerable voice, which can scarce be expected to captivate the heart, but it may influence it. Her character is of a middle sort; not handsome, but not ugly; serious, reserved, and not very attractive; though her personal beauty, as I said before, is quite lost on me."

Please note that this is an excerpt from the 1998 eBook edition of "Pride and Prejudice" with the most recent update being October 29, 2024.

You: what is Release date?
WARNING:leann.api:  ⚠️  Requested top_k (20) exceeds total documents (1)
WARNING:leann.api:  ✅ Auto-adjusted top_k to 1 to match available documents
ZmqDistanceComputer initialized: d=768, metric=0
LEANN: Based on the provided context, I'm going to take a close look at the information.

The release date mentioned in the question is June 1, 1998.

However, according to the text, the book was "most recently updated" on October 29, 2024. This implies that there have been changes or updates made to the text since the original publication of the book, specifically after January 1, 2025 (not 2024).

You: exit
Goodbye!

النص
Title: Pride and Prejudice

Author: Jane Austen

Release date: June 1, 1998 [eBook #1342]
                Most recently updated: October 29, 2024

Language: English


الصيغة دى تعمل باقى الصيغ لاتعمل









Release date

!leann ask /content/leann/.leann/indexes/my-docs --model llama3.2:1b --query"What is the author’s name"

!rm -rf /content/leann/.leann/indexes/my-docs

!ollama list

!leann build my-notes \
  --docs ./data \
  --embedding-mode ollama \
  --embedding-model nomic-embed-text:latest \
  --embedding-api-base http://127.0.0.1:11434/v1 \

!leann build my-notes --docs ./data --embedding-mode ollama --embedding-model nomic-embed-text:latest --embedding-api-base http://localhost:11434/v1

"""### شغال"""

!leann build my-notes --docs ./data --embedding-mode ollama --embedding-model nomic-embed-text:latest

!leann ask my-notes \
  --llm ollama \
  --llm-model qwen3:14b \
  --host http://192.168.1.101:11434

what is Release date?--query"What is the author’s name"

!leann ask my-notes --query "What is the author’s name"--llm ollama --llm-model llama3.2:1b --host http://localhost:11434

!leann ask my-notes --query "What is the author’s name"

from leann import LeannSearcher

searcher = LeannSearcher("/content/leann/.leann/indexes/my-notes/documents.leann.meta.json")
results = searcher.search("What is the author’s name", top_k=10, recompute_embeddings=False)

!leann ask my-notes --query "What is the author’s name" --llm ollama --llm-model llama3.2:1b --host "http://localhost:11434"

!leann ask my-notes -h

"""## شغالة"""

!leann ask my-notes --llm ollama  --model llama3.2:1b -i

"""### شغال"""

!leann build my-index --force --no-recompute --no-compact


from leann import LeannSearcher

searcher = LeannSearcher("/content/leann/.leann/indexes")
results = searcher.search("What is the author’s name", top_k=10)

#!leann build my-index --force --no-recompute --no-compact


from leann import LeannSearcher

searcher = LeannSearcher("/content/leann/.leann/indexes/my-index")
results = searcher.search("What is the author’s name", top_k=1)

!python apps/document_rag.py --query "What are the main techniques LEANN explores?" \
  --index-dir /content/leann/.leann/indexes/my-notes \
  --llm ollama --llm-model gpt-oss:20b --thinking-budget high